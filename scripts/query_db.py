import chromadb
from sentence_transformers import SentenceTransformer


print("ğŸ”„ Loading embedding model into memory...")
model = SentenceTransformer("all-mpnet-base-v2")
print("âœ… Embedding model loaded!\n")


print("ğŸ”„ Connecting to Chroma vector database (persistent on disk)...")
client = chromadb.PersistentClient(path="./vector_db")
print("âœ… Chroma vector database loaded into memory!\n")


print('ğŸ”„ Loading "fintech_services" collection...')
collection = client.get_or_create_collection(name="fintech_services")
print('âœ… Collection "fintech_services" ready!\n')


def get_relevant_chunks(query: str, top_k: int = 5) -> dict:
    """
    Retrieves the top-k relevant chunks from your vector database based on the user query.

    Returns:
        dict with keys:
            "documents": list of chunk texts,
            "metadatas": list of corresponding chunk metadata dicts
    """
    print(f"\nğŸ” Retrieving {top_k} chunks for query: {query}")

    embedding = model.encode(query).tolist()

    results = collection.query(
        query_embeddings=[embedding],
        n_results=top_k,
    )

    documents = results.get("documents", [[]])[0]  # List[str]
    metadatas = results.get("metadatas", [[]])[0]  # List[dict]

    return {
        "documents": documents,
        "metadatas": metadatas
    }
